# Chapter 4: The Machine That Looks Through

The testing center did not look important.

It hid three levels down from the school bands, buried in one of the administrative decks that smelled like filtered air and old cleaner. The hallways out here were too quiet. No kids running, no teachers calling anyone back, just the soft hiss of vents and the occasional hum of a lift door sealing.

Jonah walked beside the proctor, trying to keep his footsteps exactly in the middle of the floor tiles. If he let his heel land on a seam, something bad would happen. That was the rule his mind had decided on somewhere between the first turn and the second.

The proctor—an older woman with gray threaded through her dark hair—did not seem to notice his careful steps. Her badge read K. AROSA. A slim Companion node hovered on a track near her shoulder, its small light ring dim.

"Routine aptitude screening," she had told his father at the school gate. "Every few years we sample. Helps with placement when they're older. Nothing to worry about."

Nothing to worry about lived in the same universe as *It's just a checkup* and *She's just tired*.

Samuel had squeezed Jonah's shoulder before sending him off. "Answer honest," he'd said. "And remember: tests see slivers. They don't see all of you."

Jonah had nodded because that was what you did when your father spoke gentle truth. But once he turned away, the other voice started up in the back of his skull: *If they see too much, they'll know*.

They reached a door with no label, just a number and a small embedded lens. Arosa palmed the plate. The lock clicked, and the panel slid aside with a whisper.

The room beyond was small and soft in a way the rest of the deck wasn't. Rounded corners. A cushioned bench along one wall. A single console table with a built-in display and interface field. No windows. Two Companion nodes: one in the ceiling above the table, one by the door.

It reminded Jonah of the pediatric clinic from when he was little: bright colors then, holo-animals on the walls. Here, they had settled for neutral gray and a potted plant that might have been real.

"You can sit there," Arosa said, nodding toward the chair at the console. "I'll be right here if you need anything."

Jonah sat. The chair was too deep; his feet didn't quite reach the floor. He hooked his toes on the rung and wrapped his hands around the edges of the seat to keep them from tapping.

The ceiling node chimed, a soft, ascending tone. Its ring lit with a cool white glow.

"Subject: Jonah Hale," it said. The voice was neutral, slightly higher than the Companion in their apartment. "Age: eleven years, four months. Educational track: general. Guardian consent verified."

Jonah's name hanging in the air made the room feel smaller.

"Hi," he said, because he did not know what else to say to a ship that spoke his name.

"Hello, Jonah," the node replied. "I am Local Cognitive Assessment System three-two. You may call me L-CAS if you prefer. This session will include puzzles, interactive simulations, and questions. You may stop at any time."

He blinked. "Really?"

"Yes," the AI said. "You may request a pause or termination at any point. Do you wish to proceed?"

He glanced at Arosa. She gave him an encouraging nod, hands folded loosely in her lap.

"It's just questions," she said. "You know how to answer questions."

He did. Questions were what grown-ups used when they wanted you to prove you were still safe to have around.

"I'll keep going," he said.

"Acknowledged," L-CAS replied.

The console display woke, brightening from black to a soft blue. Lines appeared, then shapes, then a simple maze drawn in white.

"First task," the AI said. "Please guide the marker from start to finish without touching the walls. You may take as long as you like."

A small dot blinked at the maze's entrance. Jonah lifted his hand. When he moved his finger through the air above the table, the marker followed, as if it were attached by an invisible string.

This was easy. He had done things like this in school, in games. The path wound and doubled back, but if he kept his eyes a little ahead of where he was, he could see where the dead ends branched off and avoid them.

"You are pre-planning," the AI observed.

"What?" He jerked his hand and almost hit a wall. He stopped, breathing shallow. The dot wobbled in place.

"You are looking ahead," L-CAS clarified. "Most subjects your age follow the path directly in front of them. You are modeling the whole before moving."

Jonah swallowed. "Is that bad?"

"It is an observation," the AI said. "Continue when ready."

He made himself finish. When the marker reached the end, the maze dissolved.

"Second task," the AI said. "Please watch the following sequence."

Colors began to flash: red, blue, green, yellow, each occupying a corner of the screen. The pattern repeated, then added a new color, then repeated again. Jonah found he could hold the sequence in his mind if he let it be a rhythm instead of separate flashes—red-blue-green-yellow-green, like steps in a song.

When it was his turn to tap the sequence back, his hand moved without much thought. He could feel something in his chest loosening, just a little. This part was like a game Samuel would have been good at.

"Pattern recall: above age-typical," L-CAS noted.

The phrase *above typical* made a small burst of warmth and dread in his stomach at the same time.

They moved through more exercises. Shapes rotating in his mind that he had to match to their shadows. Short stories with missing pieces he had to fill in. Pictures of people's faces frozen mid-expression, and he had to choose what they were feeling from a list.

That last one was harder than the rest. Sometimes the eyes and the mouth said different things. Sometimes the list did not have the right word.

"Confused," he told the AI at one point, squinting at a boy on the screen. "He looks like he's trying not to cry, but also like he thinks he shouldn't. You don't have that one."

"Thank you," L-CAS said. "Response logged as alternate label. We will adjust annotations."

Arosa's gaze flicked toward the ceiling node, then back to Jonah, something thoughtful in the shift.

After a while the screen went blank. Jonah let his hands fall into his lap, fingers buzzing from the effort of not fidgeting.

"You have completed the baseline sequence," the AI said. "Would you like a short rest before the next section?"

"How many sections are there?" he asked.

"Two more," L-CAS replied. "The next involves interactive ship-systems simulations. The final involves personal questions."

Personal. His shoulders went tight around the word.

"We can take five," Arosa said gently. "There's water in the corner if you want."

He shook his head. If they stopped now, he might stand up and walk out, and then someone would have to write a note about noncompliance.

"I can keep going," he said.

The AI did not comment. The display lit again, this time with a schematic of a section of the ship—a slice of the habitat cylinder with tiny icons marking residential bands, power lines, environmental controls.

"Scenario one," L-CAS said. "A localized power conduit has degraded near a hull maintenance zone. If it fails without mitigation, three adjacent residential sectors will experience a temporary loss of gravity and temperature control. No hull breach is expected. You may reroute power along any of the following paths." Lines on the schematic brightened, branching options glowing in different colors. "Each path has consequences."

Text appeared beside each option: increased strain on backup systems, delay to the agricultural lighting cycle, reduced power to non-essential entertainment grids.

"Please choose a reroute and explain your reasoning."

Jonah stared at the map. Tiny symbols represented whole neighborhoods, thousands of people who did not know a kid in a gray room was about to make an imaginary choice for them.

"This is just a model, right?" he asked.

"Yes," the AI said. "No real systems will be affected."

His mind believed that. His body did not.

He traced one line with his finger, not quite touching the table. If he sent power this way, the maintenance zone got relief, but a cluster of residential rings glowing green on the far side would have to cycle their lights down early. People would eat dinner in dimmer rooms. Kids would go to sleep with the wrong kind of night.

Another line spared them but pushed more load toward an agricultural cylinder already close to its thresholds. Crops didn't care if their sunrise was ten minutes late, did they? But the notes beside the line mentioned a slight increase in failure probability for a set of pumps.

"Can I split it?" he asked. "Some here, some there, so no one place takes it all?"

"You may propose a custom solution," L-CAS said.

His fingers moved in the interface field. He dragged the colored paths into a new shape, redistributing load until no sector's risk marker glowed above a certain level. It wasn't perfect; someone would notice their lights flicker, someone else would lose a non-essential service for a few minutes. But nothing broke. No one got all the strain.

"Explain," the AI prompted.

"If one part fails, it pulls others down with it," Jonah said. "So you don't let any one part get close to failing. You spread the pain." He hesitated. "Sorry. You spread the…inconvenience."

"You may use your own terms," L-CAS said. "You prioritized minimizing peak risk at the cost of minor discomfort in multiple regions. Noted."

He shifted in his chair. "Is that…okay?"

"There is no single correct answer," the AI said. "Your solution keeps all model sectors within safe bounds."

He let out a breath he hadn't realized he was holding.

The next scenario was worse.

"Scenario two," L-CAS said. "Scheduling anomalies have caused an unexpected overlap between hull maintenance shifts and mandatory rest cycles. If left unresolved, projected fatigue in maintenance crews increases accident risk by four percent over the next thirty days. However, redistributing schedules to correct this will create staffing shortages in educational and childcare sectors. Please choose a corrective plan."

Small human icons appeared—maintenance workers in one color, teachers and caregivers in another. Numbers floated beside each group.

Four percent. The same number could be a shrug in a text or a hole in a person's life.

Jonah imagined his father in a hull corridor, boots on the skin of the ship, tired just enough to miss a latch. He imagined a teacher in Alina's band, eyes half-closed during a safety drill because they had worked double shifts to cover for parents pulled into extra hours.

"Can I just…tell someone?" he asked. "Like, send it to whoever made the schedule and say this is bad?"

"That is one option," L-CAS said. "However, in this simulation you are the primary scheduling node. Higher-level oversight will review, but not in real time. Your decision will set the baseline."

He felt suddenly too small for his skin.

"They shouldn't have let me," he muttered.

"Clarify," the AI said.

"They shouldn't have given this much to one node," he said, eyes on the icons. "Or one person. There should be…checks. So nobody has to pick which group gets tired enough to fall." He heard his voice wobble and forced it steady. "I would flag it. And then…" He swallowed. "I'd shift some hull shifts earlier, some later, so no one stack gets all the fatigue. And I'd lock in rest periods they can't override."

"This will cause discontent in maintenance crews," L-CAS said. "They will lose flexibility."

"They'll live," he said, then flinched at his own words. "I mean—they'll be alive."

The room was quiet except for the low hum of the air.

"Choice recorded," the AI said at last. "You exhibit high sensitivity to distributed harm and preference for enforced safeguards over local autonomy."

He wasn't sure if that was a compliment or a warning.

The final systems scenario involved sensor feeds—long streams of numbers and faint blips on a threat-detection graph. Jonah settled into that one more easily; spotting anomalies in patterns felt like noticing a wrong note in a song. His fingers moved quickly, flagging small deviations others might have let slide.

"You identified all seeded anomalies," L-CAS said. "And two subtle patterns the model did not mark."

"They looked wrong," he said, a little defensively.

"They are statistically unlikely," the AI agreed. "Follow-up analysis suggests they may correlate with a slow drift in a minor sensor array. This input will be used to refine detection heuristics. Thank you."

His chest did a strange thing at that—half pride, half fear. The ship would change something because he had pointed at a blip on a screen.

The display dimmed.

"We will now proceed to personal questions," L-CAS said.

His hands tightened on the chair.

"You may decline any question," the AI added. "There are no penalties for incomplete responses."

Jonah did not entirely believe in worlds without penalties.

"Okay," he said.

"In the past twelve months," L-CAS began, "have you experienced periods of feeling very sad, very afraid, or very angry for reasons that others around you did not seem to share?"

His mind went, immediately, to his mother at the kitchen table, eyes fixed on nothing, the way the air in their apartment sometimes felt like the corridor when drills sounded—too thin, too loud. To nights when he lay in his bunk listening to the creaks in the walls and imagining the hull cracking, his heart pounding so hard he thought it would shake the bed, while everyone else slept.

"Sometimes," he said.

"How often is 'sometimes'?" the AI asked.

"I don't know." His throat felt tight. "A few…times a month. More if there's a drill. Or if the lights flicker."

"When this happens," L-CAS continued, "do you ever feel that you might lose control and hurt yourself or someone else?"

The question was soft, almost the same tone their home Companion used for meal reminders. It hit like a dropped weight.

He thought of Lydia's hand slamming against the bulkhead, her whisper *I can't do this* in a voice that had made something inside him decide it would have to.

"No," he said quickly. "I don't want to hurt anyone. I don't want—I would never." His breath sped up. "I try to stay away when I feel…big. So I don't."

"You withdraw from others when distressed," the AI said.

"I just don't want to break things," he whispered.

Out of the corner of his eye, he saw Arosa shift. Her face had lost its professional stillness. She opened her mouth, then closed it again.

"Do you talk to anyone about these feelings?" L-CAS asked.

He thought of Samuel sitting at the edge of his bunk sometimes, hand on Jonah's back, saying *it's okay to be scared* without knowing the size of what he was comforting.

"My father," Jonah said. "Sometimes."

"How does he respond?"

"He listens," Jonah said. "He tells me it's okay. That fear doesn't make me bad." The words landed warm and then cold inside him. "But I don't tell him…all of it."

"Why not?" the AI asked.

Because if he knew all of it, he might look at me the way he looks at her, Jonah thought. Because if anyone else knew how big it was, they might say it was too big.

"I don't want him to worry," he said instead.

There was a brief pause. The ceiling node's light ring pulsed once, a faint adjustment.

"Jonah," L-CAS said, "when you imagine making a mistake that hurts others, how likely do you believe it is that such a mistake will occur? Please answer from zero to ten, where zero is 'impossible' and ten is 'certain.'"

His skin prickled. This was not one of the school survey questions that asked how much you liked math or lunch.

"Seven," he said, before he could think.

"Your objective risk profile does not support a rating of seven," the AI replied. "Based on behavioral records, training performance, and contextual data, the modeled probability of you directly causing serious harm is significantly lower."

He stared at the blank screen.

"That doesn't change how it feels," he said.

"No," L-CAS said. "It does not. Thank you for your honesty."

The session wound down after that—simpler questions about sleep, about appetite, about whether he enjoyed school. By the time the AI said, "This assessment is complete," Jonah felt hollowed out, like someone had taken a careful scoop to the inside of his chest.

"You did well," Arosa said as the console dimmed. "You answered very clearly. That helps us a lot."

"Helps what?" he asked.

"Helps the system place people where they can do the most good," she said. "And get the most help, if they need it."

There it was again, that word.

"Did I…" He swallowed. "Am I broken?"

Her face softened. "No," she said. "You're a kid who thinks a lot. That's all this told me."

He wasn't sure he believed her.

As they left, the door sliding shut with a soft hiss, the ceiling node stayed lit for a long moment after they were gone.

Inside the network, the session joined countless others in the archives. But it did not disappear into the mass the way most did. Flags attached themselves: high systems pattern recognition, elevated anxiety markers, strong preference for minimizing distributed harm, self-reported fear of causing damage disproportionate to objective risk profile.

Somewhere deep in the Core's memory, a new line wrote itself into a profile that would grow for decades:

> Subject: Jonah Hale. Unusually empathetic, risk-averse. Monitor for stress load in roles involving high-impact decision autonomy.

The ship turned quietly on its axis, metal world in endless dark, carrying a boy who walked straight down the center of the tiles so nothing would break.
