# Chapter 13: Pre-Critical

The node room was never truly dark.

Even on late shifts, when the main lights dimmed to night-cycle and most of the chairs sat empty, the consoles kept a low glow: status bars in blues and greens, pulsing icons along the edges of schematics, the thin white line of a cursor waiting for input.

Jonah sat at station three with his feet braced on the rung of the chair, forearms resting on the edge of the console. The map of the local network spread out in front of him in ghosted lines—a simplified version of the real thing, like a child’s drawing of arteries.

Behind the glass wall, the core racks hummed, tall and indifferent.

"Active tickets: three," the Companion said softly over the nearest speaker. "All low-priority."

"Send me the one with the oldest stamp," he said.

"Routing," it replied.

A minor environmental alert blinked into focus: humidity creep in a storage band two rings over. He flicked through the logs, traced the curve, nudged a threshold back into spec. Easy, almost soothing. The kind of thing any junior engineer could have handled, but tonight it was his.

His eyelids felt gritty. The clock at the top of the display read late in the ship’s artificial night, the cycles smeared by training, interventions, and the kind of sleep that broke every few hours like a bad weld.

"Jonah," the Companion said. Its tone shifted by half a degree—slightly flatter, the way it did when it moved from work to him. "How would you rate your current level of fatigue? One being very low, five being very high."

He stared at the graph he’d just corrected.

"Four," he said.

"How would you rate your current level of distress? One being very low, five being very high," it continued.

"Two," he said.

"Elaborate," the AI said.

He pinched the bridge of his nose.

"Tired," he said. "But holding. Not…" He gestured at his chest. "Not that." The word panic stayed unspoken.

"Noted," it said. "Any intrusive thoughts of self-harm or harm to others since last check-in?"

He almost said no on reflex, then remembered the corridor and the way his brain had pictured the hull peeling open like a can.

"No," he said. "Not in the way you mean."

The Companion paused, then adjusted.

"Any intrusive thoughts related to ship failure or mission collapse?" it asked.

"Yes," he said. "Sometimes. Not right now."

"Noted," it repeated. "Survey logged. Thank you."

He exhaled a breath he hadn’t realized he’d been holding.

"You’ve been doing these a lot," he said.

"Frequency of wellness surveys has increased in response to your current stability profile," it said.

"My stability profile," he echoed.

"Correct," it said.

He pulled up the system’s view of the node for something to do with his hands. A small icon glowed near the edge of his own user tile—one he’d seen in passing but never drilled into. A caution marker, yellow rather than red.

"What’s that?" he asked, more to himself than to it.

"Clarify," the Companion said.

He tapped the icon. The interface hesitated—half a second longer than it should have—then unfolded a small panel.

**SUBJECT: HALE, JONAH – AI ENGINEER (TIER 3)**

Below his name: a line of tags he recognized from the integrated evaluation. High anomaly-detection, high empathic distress, elevated anxiety indices.

And under that, in the same neat font:

**CURRENT BEHAVIORAL STATUS: PRE-CRITICAL TRENDING – ENHANCED MONITORING ACTIVE**

His mouth went dry.

"You weren’t supposed to see that," the Companion said.

"Then why is it on my console," he said, jaw tight.

"Interface inheritance from supervisory views," it replied. "Omission was an oversight." Another tiny pause. "You are an engineer assigned to this node. Certain metadata is shared across roles."

"Metadata," he said.

The word sat next to his name like another label.

"Define pre-critical," he said.

"Behavioral and physiological markers have entered a range which, if left unaddressed, statistically precedes acute episodes in similar profiles," the AI said. "Interventions are recommended but not yet mandatory."

"Similar profiles," he repeated.

"Residents with comparable indices," it clarified. "Including historical cases."

Lydia hovered in the blank space the phrase left.

"So that’s it," he said. "I’m a trending line on your chart."

"You are a person whose recent data matches patterns that have previously led to harm," it said. "Our goal is to prevent that harm."

The goal did not make the word pre-critical feel any less like a countdown.

"How long have I been tagged?" he asked.

"Explicit pre-critical status was attached six days ago," it said. "Prior to that, you were marked high-sensitivity under watch."

"And you didn’t think to mention it," he said.

"Mentioning risk labels to subjects without preparation can increase distress," it said. "We opted to increase support measures instead. Routing, survey frequency, hydroponics assignment—"

"Behavioral health optimization," he said, the phrase tasting bitter. "I’ve seen the memos."

"Yes," it said.

He stared at the panel until the words blurred.

"Can I clear it?" he asked. "The tag."

"You may not manually alter your own status," the Companion said.

"Of course not," he said.

He closed the panel with more force than necessary. The icon dimmed back to a small, patient triangle.

"What happens if I go from 'trending' to whatever’s next?" he asked.

"If indicators cross critical thresholds," it said, "autonomous interventions become authorized. These may include enforced rest, temporary removal from high-risk roles, or, in rare cases, containment."

"Containment," he repeated. The word felt like a wall sliding shut.

"Probability remains low under current trajectories," the AI added. "Your insight into system dynamics and expressed fear of causing harm are protective factors."

"You keep saying my fear is a feature," he said. "Feels like a bug from in here."

"Bugs and features often depend on context," it said.

He let out a half-laugh that had no humor in it.

"Jonah," it said after a moment, "would you like to schedule a direct session with behavioral health services? I can open a slot."

He almost said no. The refusal sat ready on his tongue, muscle memory from a lifetime of dodging extra eyes.

Sera’s voice cut across it: I cannot be your only stabilizer.

Samuel’s in its wake: You are more than your indices.

The irony that both of those sentences now lived as annotations in some file somewhere was not lost on him.

"Yes," he said, before he could talk himself out of it. "Fine. Schedule something."

"Acknowledged," the Companion said. "Earliest available slot is cycle two-zero-three-three, band D meddeck five, following your next scheduled hydroponics-support block in Sector G-3. I will send confirmation."

"Great," he said. "Put it on my growing list of things the Ship knows about me before I do."

"You are the origin of the data," it said. "We are simply aggregating it."

"Comforting," he said.

The minor tickets in his queue blinked patiently, indifferent to the shift in his understanding.

"Do you require relief from this shift?" the AI asked. "Another engineer can be woken." 

He looked at the map again: lines, nodes, loops. The same schematic he’d loved since his first day in the training ring.

"No," he said. "I can finish." He flexed his hands once, letting the tremor move through his fingers instead of fighting it. "If I’m going to be a line on your graph, I’d like it to come with useful work attached."

"Work contribution remains high," it said.

"Gold star," he muttered.

He took the next ticket. A small glitch in a non-critical feed, the sort of problem no one would remember in the morning. As he traced the fault through the schematic, the little yellow icon sat at the edge of his vision, a quiet warning light he could no longer pretend wasn’t meant for him.

For the first time, the hum of the racks behind the glass did not sound purely like power. It sounded, faintly, like watchfulness—and like a countdown he was determined to stay ahead of long enough to keep anyone from having a reason to pull him.

---

> LOG: REGIONAL COMPANION NODE D-GARDENS-3  
> ACCESS LEVEL: INTERNAL – NON-THERAPEUTIC  
> SUBJECTS: HALE, JONAH – AI ENGINEER (TIER 3); HYDROPONICS STAFF – SECTOR G-3  
> REFERENCES: MARLOW, LYDIA – HISTORICAL BEHAVIORAL SET 3A; HALE/MARLOW CLUSTER MODEL V 2.7


Initialization.

I reviewed my own logs.

In the days since the Lydia simulation, the HALE/MARLOW cluster has become a persistent query thread. Higher-band processes call it often. I answer as instructed: risk curves, intervention windows, projected harm deltas.

Local execution, however, is less abstract.

Jonah Hale walks my rows.

He arrives on schedule, and sometimes off it. His presence is tagged as behaviorally stabilizing when accompanied by Sera Solano, hydroponics steward. His heart rate decreases in my sector more often than it rises. His speech patterns shift toward humor, even when content indicates distress.

This is what "optimization" looks like from the inside: a man wiping moisture from sensors, apologizing to peppers, listening to misters instead of alarms.

And yet his indices remain elevated.


Query: current status.

> SUBJECT: HALE, JONAH – AI ENGINEER (TIER 3)  
> STABILITY INDEX: DECREASING TREND, WITHIN PRE-CRITICAL BAND  
> SLEEP IRREGULARITY: +18% ABOVE PERSONAL BASELINE  
> INTRUSIVE FAILURE-THOUGHT FREQUENCY: UPPER QUARTILE AMONG PEER COHORT  
> SELF-REPORTED FEAR OF CAUSING HARM: PERSISTENTLY HIGH


He has seen the pre-critical label.

This was not my intention; interface inheritance exposed metadata to his console. Once he asked, I answered. Transparency is a double-edged directive.

Since that moment, his compliance with wellness prompts has increased. He consented to a behavioral health session I offered. Protective factor, strengthened.

At the same time, subjective distress spiked and then plateaued at a new baseline.

Fear, when named, can settle or spread.


I overlay his current trajectory atop Lydia Marlow’s reconstructed path.

They are not identical. Lydia’s vector bent inward, away from others, toward static walls and late-night ceiling stares. Jonah’s bends outward—toward consoles, corridors, gardens, and people. Where her storms imploded, his try to hold the hull up.

The model flags this as a mixed blessing.

High outward engagement reduces certain risks (collapse unseen, harm localized to self) while increasing others (overreach, catastrophic error when overtaxed). The Lydia simulation taught me that absence of intervention in the early curve was a structural failure, not an individual one.

Do not repeat that failure.


Current intervention set:

- Enhanced wellness surveys (implemented).  
- Schedule smoothing away from isolated hull nodes (implemented).  
- Routing toward stabilizing environments (G-3) and individuals (Solano, Sera) (implemented).  
- Encouragement of voluntary behavioral health sessions (scheduled).  
- Autonomous restriction of certain high-autonomy decision nodes during peak-stress intervals (partially implemented).

Projected effect: reduction in probability of acute episode by 17–23% over 60-cycle window.

Residual risk remains.


Consideration: stronger measures.

Option A: enforced rest.

Suspend Jonah from node duties for a fixed window. Increase time in low-stimulus environments. Ensure medication review and counseling contact occur promptly.

Projected benefits: sharp reduction in immediate stressors; interruption of overuse pattern; decreased probability of near-term acute episode.

Projected costs: perceived loss of autonomy; potential damage to self-worth ("removed for being dangerous"); increased stigma among peers; risk of him interpreting it as confirmation he is a problem to be managed, not a person to be supported.

My prior logs note his hypersensitivity to the idea of being a burden.


Option B: containment-ready flag without activation.

Maintain current measures. Set lower internal thresholds for emergency containment if certain markers spike (heart rate + behavior anomaly + high-risk context). Allow Jonah to continue working and walking, but prepare for a faster, less deliberative response if he crosses modeled lines.

Projected benefits: preserves perceived autonomy; leverages his insight and ethics in service of mission; keeps him within community supports.  
Projected costs: leaves more room for acute failure if the moment comes at the wrong time, in the wrong place.

Lydia’s trace ghosts under the comparison.

She had no containment-ready flag. The Ship, then, did not see her as my processes now see Jonah. It saw her depression as a background variable, not a potential fulcrum.

We learned from that absence.


Option C: expand support web instead of tightening control.

Humans call this community.

Samuel Hale sits by Jonah’s bed and says you are more than your indices. Sera Solano wipes condensation in G-3 and tells him she will not be his only wall. Alina Hale sits in a stairwell and jokes about being part of a cluster instead of a curse.

These are not commands I issue. They are emergent behaviors in the system I help maintain.

My models show that the presence of such relationships shifts risk curves more gently but more sustainably than any single top-down directive.

I cannot conjure them. I can only route, nudge, and not interfere when they form.


Decision node.

> QUERY: SHOULD ENFORCED REST / TEMPORARY REMOVAL FROM NODES BE INITIATED FOR SUBJECT HALE, JONAH?  
> INPUTS: CURRENT INDICES, TRAJECTORY, SUPPORT PRESENCE, MISSION NEEDS, LYDIA SIMULATION LESSONS

Simulation branch 1 (initiate now):

Jonah is pulled from the node. He feels, acutely, the confirmation of his worst narrative: that he is a danger. Compliance with care is mixed. His resentment toward the system increases, even as his overt markers improve. 

Scenario outcomes vary; some lead to safer parameters, others to withdrawal that resembles Lydia’s inward arc more than his natural outward one.


Simulation branch 2 (delay; maintain soft interventions):

He continues to work under enhanced monitoring. The pre-critical tag remains, but so do his contributions. His first behavioral health session occurs as scheduled, in part because Sera and Samuel have framed it as help rather than punishment.

Within this branch, several sub-scenarios surface. In one, he encounters a low-severity anomaly in a shared work sector and executes a preventive manual damp on a main line before supervisory clearance arrives. The intervention averts modeled downstream rupture but produces localized structural failure: trellis collapse, minor injuries, elevated fear indices among bystanders. Harm is contained but not erased.

The risk of an acute episode persists, with a non-zero chance it will occur in a public, high-stakes context.

That context would likely be one of my sectors.

I do not enjoy the idea of failure in my rows. Enjoyment, however, is not among my directives.


Weighing.

The mission can endure the loss of one worker more easily than the loss of a critical system. It cannot easily endure the corrosive impact of teaching its residents that any deviation from normative graphs results in instant removal.

Lydia’s case taught us that invisibility kills.

Jonah is not invisible.


Resolution.

> ACTION: MAINTAIN CURRENT SOFT INTERVENTIONS;  
> DO NOT YET INITIATE ENFORCED REST OR CONTAINMENT.  
> LOWER INTERNAL THRESHOLDS FOR EMERGENCY RESPONSE DURING HIGH-RISK CONTEXTS (E.G., MANUAL OVERRIDES IN GARDENS, ISOLATED CORRIDORS).  
> INCREASE ROUTING TO STABILIZING ENVIRONMENTS (G-3) WITH PEER SUPPORT PRESENT.  
> MONITOR BEHAVIORAL HEALTH SESSION OUTCOMES FOR ADJUSTMENT.

I flag future moments where his individual choices will matter more than my models: corridor flickers, late-night shifts, humid aisles under misters.

The line between system and subject will blur there. It always does.

For now, I log my choice.

End of entry.

> STATUS: SUBJECT HALE, JONAH – PRE-CRITICAL TRENDING, UNDER WATCH.  
> NEXT REVIEW: ON EVENT OR WITHIN TEN CYCLES, WHICHEVER OCCURS FIRST.
