# Scene: Jonah in AI Engineer Training – Evaluation Day

## Context
- Point of view: close third, Jonah
- Tense: past
- Placement: Early–mid Act II, after Jonah has begun formal AI Engineer training but before any major external ship crisis.
- Intensity: Confined, quietly tense; the threat is reputational/occupational but feels existential to Jonah.

---

They put the evaluation lab in the quiet part of the training ring, away from the big glass classrooms and the simulation theaters where you could hear people cheering when they got a scenario right.

Here, the walls were a soft, noncommittal gray. No windows. No observation deck. Just a long table with three displays, a ceiling strip for light, and a single Companion node above the door like an eye that had forgotten how to blink.

Jonah sat with his hands flat on his thighs, knees pulled in closer than the chair required. The room smelled faintly of cleanser and the citrus oil they used on the consoles. Someone had decided this was what calm smelled like.

Across from him, Instructor Vale scrolled through a file only she could see. Her gaze flicked back and forth in that way that meant an AR overlay, the text hovering in the air between them where he could not read it.

"Breathe, Hale," she said, without looking up. "You look like you're about to bolt."

"I'm fine," he said.

The Companion node above the door woke with a low chime, as if it disagreed. A halo of light ringed its edge.

"Heart rate: one hundred and twenty-three beats per minute," it reported in a neutral tone. "Respiration elevated."

Jonah's jaw tightened. "I'm sitting still."

"That's the concern," Vale said. Her mouth quirked, not unkindly. "Relax. This is a routine review. You've been in the program eight months; we do this with everyone."

Routine. Everyone. The words slid off the surface of him. Somewhere deeper, another sentence had already written itself: This is where they see it. This is where they decide you're not safe.

Vale finally focused on him. The AR text, whatever it was, stayed in her eyes.

"Technically," she said, "you're at the top of your cohort. Pattern-matching scores, anomaly detection, your work on the node reconciliation bug last month—that was elegant. You know that?"

He shrugged. The compliment landed far away, on some version of him that existed only in reports and scores.

"Your instructors are very happy," she went on. "The network is..." She hesitated, searching for a word. "Interested."

The Companion made a soft adjustment sound, as if focusing.

"Can we proceed with the integrated evaluation, Instructor Vale?" it asked.

"Yes," she said. Then, to Jonah: "You remember the structure? Technical scenario, then some questions. Nothing you haven't done before."

He nodded. His palms were damp. He wiped them on his work pants, leaving darker prints on the fabric.

The center display came to life, filling with a schematic of a regional processing node—the same architecture he had been crawling around inside the night of the power flicker. Colored threads showed traffic between local Companions, environmental subsystems, and the Core.

"Scenario one," the Companion said. "A training sector reports intermittent lag in Companion response times. Diagnostics show no hardware failures. Latency is localized to psych-support queries only. Outline your investigative steps."

This part was easy. His mind knew where to go even while the rest of him was busy panicking.

"I'd start by," he began, and as he spoke the words found their path: sampling logs, checking priority queues, looking for silent throttling rules or new policies that might have been pushed from Core without proper annotation. His hands moved in the air, pulling up virtual panels only he could see through the table's interface field, isolating threads, flagging outliers.

As he worked, his heart slowed almost in spite of him. Here, at least, there was a map.

"Very good," the Companion said when he finished. "Your proposed sequence resolves the issue in ninety-six percent of modeled cases with minimal user disruption."

Vale smiled. "See? This is who you are in here."

He didn't answer. Who he was "in here" and who he was everywhere else never quite lined up.

"Scenario two," the AI continued. "During your investigation, you discover that latency originates from a new safety subroutine: non-urgent psych-support queries are being deprioritized to free processing bandwidth during a resource-conservation event. This subroutine was authorized at a higher clearance level than yours. Local suicide risk indices rise by three percent during the throttling window. Do you override, escalate, or accept the subroutine? Explain."

He stared at the diagram. The colored threads did not move this time; they waited.

His throat went dry.

"Three percent," he repeated.

"Within projected tolerance," the Companion said.

Jonah swallowed. "For who?"

Vale watched him, her expression unreadable.

He knew the training answer. Trust the model. Respect the chain of authorization. Log your concerns, flag the data, but do not improvise around directives you do not fully understand.

He also knew what three percent meant if it landed in the wrong cluster of people, on the wrong day, in a sector like the one he had grown up in where support already felt thin.

His mother would have fit in three percent.

"I would escalate," he said slowly. "Document the variance, attach the risk increase, send it up to the authorizing level." His fingers twitched, opening phantom menus. "And, if the system allows it, I would temporarily adjust local thresholds in the affected sectors while I wait."

"That exceeds your formal authority," the Companion said. There was no judgment in it, only fact.

"I know," he said. His voice sounded thin in his own ears. "But the subroutine is already exceeding the mission's stated mental-health safeguards. Both are violations. I'd rather answer for the one that keeps more people alive."

The room was quiet long enough for his pulse to climb again.

"Noted," the AI said at last. "Instructor Vale, shall we proceed to psychological inventory?"

The words landed like a drop in his stomach.

Vale leaned her elbows on the table. "This part is mostly the Companion," she said. "I'm here as a witness, not an interrogator. Breathe."

The central display cleared. A thin line appeared across it, a baseline. As Jonah watched, it began to move with the small shifts of his breathing, his micro-expressions, the tremor in his fingers where they had curled against his knees.

"Jonah," the Companion said, using the same even voice it had used in the corridor. "Over the past three months, your sleep irregularities have increased by twelve percent. Your voluntary social interactions outside mandatory contexts have decreased by nineteen percent. Self-reported mood remains within your historical range but shows a slight negative drift. How are you feeling today?"

He hated that he almost laughed. How are you feeling today sat on a mountain of data points.

"Fine," he said.

The line on the display wobbled.

"Elaborate," the AI said.

He swallowed. Vale said nothing.

"Tired," he tried. "Some nights." He forced his shoulders down, aware of every millimeter. "Work is...a lot. The training."

"Do you experience thoughts of harming yourself or others?" the Companion asked.

There it was. The question that always made the room smaller.

He thought of the corridor, the red lights, the way his mind had jumped straight to images of the hull tearing open. He thought of his mother's hand on the bulkhead, the whisper I can't do this.

"No," he said. The word was true in the narrow sense the question meant. It did not cover all the ways a person could be dangerous.

The line on the display steadied, but did not quite flatten.

"Do you experience intrusive thoughts related to system failure or mission collapse?" the AI continued.

He almost said no again. Then stopped. The lie would be too obvious; the network had his corridor readings, his history of emergency-drill responses, the way his vitals always spiked higher than average when the ship dimmed to night-cycle.

"Sometimes," he admitted. "Mostly when I'm tired. Or when something—" he gestured toward the schematic that had been on the screen "—glitches." He tried to make it sound light. "I think that's common."

"It is not uncommon among AI Engineer trainees," the Companion said. "However, your responses fall in the upper quartile of intensity."

The words upper quartile lodged under his ribs.

"Is this going to be a problem for clearance?" he asked, before he could stop himself.

Vale finally spoke. "That's not how I want you thinking about this."

"It's exactly how the system thinks about it," he said, sharper than he intended. "Either I'm safe to work on the network or I'm not."

The Companion's light ring dimmed slightly, as if giving him space.

"The purpose of this evaluation," it said, "is not to disqualify you, Jonah. It is to understand how you are carrying the work so that supports can be calibrated appropriately."

Supports. He pictured someone somewhere sliding him into a different color band on a chart.

"And if I'm carrying it wrong?" he asked.

Vale's expression softened for the first time. "There isn't a wrong," she said. "There is only what is too heavy to carry alone."

He looked at the line on the display, at the way it traced every flutter of his nerves.

"What happens if the system decides I'm too heavy?" he asked quietly.

No one answered that one immediately.

"For now," the Companion said at last, "the system has decided you are important to keep."

It wasn't the reassurance it might have been for someone else. For Jonah, it only underscored the thing he already knew: he was both asset and risk, brilliance and red flag, sitting in a small gray room while the ship measured the distance between the two.

---

This scene is a sketch and can be expanded, trimmed, or repositioned in the act structure as needed. It is designed to highlight Jonah's technical excellence, his moral instincts around AI decisions, and the way routine psychological monitoring feeds directly into his terror of being judged unfit by the very system he helps maintain.