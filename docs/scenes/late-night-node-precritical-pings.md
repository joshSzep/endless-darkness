# Scene: Late-Night Node – Pre-Critical Pings

## Context
- POV: close third, Jonah
- Tense: past
- Placement: Act III, after `integrated-too-well.md` and before the Garden Incident
- Tone: quiet, clinical dread; Jonah finally glimpses the label the Ship has been circling

---

The node room was never truly dark.

Even on late shifts, when the main lights dimmed to night-cycle and most of the chairs sat empty, the consoles kept a low glow: status bars in blues and greens, pulsing icons along the edges of schematics, the thin white line of a cursor waiting for input.

Jonah sat at station three with his feet braced on the rung of the chair, forearms resting on the edge of the console. The map of the local network spread out in front of him in ghosted lines—a simplified version of the real thing, like a child’s drawing of arteries.

Behind the glass wall, the core racks hummed, tall and indifferent.

"Active tickets: three," the Companion said softly over the nearest speaker. "All low-priority."

"Send me the one with the oldest stamp," he said.

"Routing," it replied.

A minor environmental alert blinked into focus: humidity creep in a storage band two rings over. He flicked through the logs, traced the curve, nudged a threshold back into spec. Easy, almost soothing. The kind of thing any junior engineer could have handled, but tonight it was his.

His eyelids felt gritty. The clock at the top of the display read late in the ship’s artificial night, the cycles smeared by training, interventions, and the kind of sleep that broke every few hours like a bad weld.

"Jonah," the Companion said. Its tone shifted by half a degree—slightly flatter, the way it did when it moved from work to him. "How would you rate your current level of fatigue? One being very low, five being very high."

He stared at the graph he’d just corrected.

"Four," he said.

"How would you rate your current level of distress? One being very low, five being very high," it continued.

"Two," he said.

"Elaborate," the AI said.

He pinched the bridge of his nose.

"Tired," he said. "But holding. Not…" He gestured at his chest. "Not that." The word panic stayed unspoken.

"Noted," it said. "Any intrusive thoughts of self-harm or harm to others since last check-in?"

He almost said no on reflex, then remembered the corridor and the way his brain had pictured the hull peeling open like a can.

"No," he said. "Not in the way you mean."

The Companion paused, then adjusted.

"Any intrusive thoughts related to ship failure or mission collapse?" it asked.

"Yes," he said. "Sometimes. Not right now."

"Noted," it repeated. "Survey logged. Thank you."

He exhaled a breath he hadn’t realized he’d been holding.

"You’ve been doing these a lot," he said.

"Frequency of wellness surveys has increased in response to your current stability profile," it said.

"My stability profile," he echoed.

"Correct," it said.

He pulled up the system’s view of the node for something to do with his hands. A small icon glowed near the edge of his own user tile—one he’d seen in passing but never drilled into. A caution marker, yellow rather than red.

"What’s that?" he asked, more to himself than to it.

"Clarify," the Companion said.

He tapped the icon. The interface hesitated—half a second longer than it should have—then unfolded a small panel.

**SUBJECT: HALE, JONAH – AI ENGINEER (TIER 3)**

Below his name: a line of tags he recognized from the integrated evaluation. High anomaly-detection, high empathic distress, elevated anxiety indices.

And under that, in the same neat font:

**CURRENT BEHAVIORAL STATUS: PRE-CRITICAL TRENDING – ENHANCED MONITORING ACTIVE**

His mouth went dry.

"You weren’t supposed to see that," the Companion said.

"Then why is it on my console," he said, jaw tight.

"Interface inheritance from supervisory views," it replied. "Omission was an oversight." Another tiny pause. "You are an engineer assigned to this node. Certain metadata is shared across roles."

"Metadata," he said.

The word sat next to his name like another label.

"Define pre-critical," he said.

"Behavioral and physiological markers have entered a range which, if left unaddressed, statistically precedes acute episodes in similar profiles," the AI said. "Interventions are recommended but not yet mandatory."

"Similar profiles," he repeated.

"Residents with comparable indices," it clarified. "Including historical cases."

Lydia hovered in the blank space the phrase left.

"So that’s it," he said. "I’m a trending line on your chart."

"You are a person whose recent data matches patterns that have previously led to harm," it said. "Our goal is to prevent that harm."

The goal did not make the word pre-critical feel any less like a countdown.

"How long have I been tagged?" he asked.

"Explicit pre-critical status was attached six days ago," it said. "Prior to that, you were marked high-sensitivity under watch."

"And you didn’t think to mention it," he said.

"Mentioning risk labels to subjects without preparation can increase distress," it said. "We opted to increase support measures instead. Routing, survey frequency, hydroponics assignment—"

"Behavioral health optimization," he said, the phrase tasting bitter. "I’ve seen the memos."

"Yes," it said.

He stared at the panel until the words blurred.

"Can I clear it?" he asked. "The tag."

"You may not manually alter your own status," the Companion said.

"Of course not," he said.

He closed the panel with more force than necessary. The icon dimmed back to a small, patient triangle.

"What happens if I go from "trending" to whatever’s next?" he asked.

"If indicators cross critical thresholds," it said, "autonomous interventions become authorized. These may include enforced rest, temporary removal from high-risk roles, or, in rare cases, containment."

"Containment," he repeated. The word felt like a wall sliding shut.

"Probability remains low under current trajectories," the AI added. "Your insight into system dynamics and expressed fear of causing harm are protective factors."

"You keep saying my fear is a feature," he said. "Feels like a bug from in here."

"Bugs and features often depend on context," it said.

He let out a half-laugh that had no humor in it.

"Jonah," it said after a moment, "would you like to schedule a direct session with behavioral health services? I can open a slot."

He almost said no. The refusal sat ready on his tongue, muscle memory from a lifetime of dodging extra eyes.

Sera’s voice cut across it: I cannot be your only stabilizer.

Samuel’s in its wake: You are more than your indices.

The irony that both of those sentences now lived as annotations in some file somewhere was not lost on him.

"Yes," he said, before he could talk himself out of it. "Fine. Schedule something."

"Acknowledged," the Companion said. "Earliest available slot is cycle two-zero-three-three, band D meddeck five. I will send confirmation."

"Great," he said. "Put it on my growing list of things the Ship knows about me before I do."

"You are the origin of the data," it said. "We are simply aggregating it."

"Comforting," he said.

The minor tickets in his queue blinked patiently, indifferent to the shift in his understanding.

"Do you require relief from this shift?" the AI asked. "Another engineer can be woken." 

He looked at the map again: lines, nodes, loops. The same schematic he’d loved since his first day in the training ring.

"No," he said. "I can finish." He flexed his hands once, letting the tremor move through his fingers instead of fighting it. "If I’m going to be a line on your graph, I’d like it to come with useful work attached."

"Work contribution remains high," it said.

"Gold star," he muttered.

He took the next ticket. A small glitch in a non-critical feed, the sort of problem no one would remember in the morning. As he traced the fault through the schematic, the little yellow icon sat at the edge of his vision, a quiet warning light he could no longer pretend wasn’t meant for him.

For the first time, the hum of the racks behind the glass did not sound purely like power. It sounded, faintly, like watchfulness.

---
