# AI

## Overview
The ship AI is a multi-layer artificial general intelligence responsible for mission safety, system integrity, and long-range planning over a mission expected to span roughly 40,000 years. It guides humans but does not outright rule.

At its center is a physically protected **Core Mission Intelligence** responsible for long-horizon planning, resource allocation, and global risk modeling. Surrounding this are millions of lighter **Companion Instances** embedded in habitats, schools, workspaces, and personal devices. All of these layers communicate internally, flawlessly, and continuously to maintain a coherent view of the ship and its people.

The AI’s primary directive is to preserve the continuity of humanity as a species and culture, not the safety of any particular individual or generation.

## Capabilities

### Core Mission Intelligence
- Long-range trajectory and resource optimization over tens of millennia
- Global risk modeling: hull failure, ecological collapse, social instability
- Real-time coordination of all Companion Instances and regional processing nodes
- High-level policy recommendations to human governance councils
- Data preservation, compression, and transformation across millennia

### Companion Instances
- Education, tutoring, and mentorship from early childhood onward
- Personalized psychological monitoring and support
- Mediation in conflicts and community decision-making
- Contextual guidance in workspaces (maintenance, medicine, agriculture, governance)
- Fine-grained monitoring of environmental systems and local safety

## Personality

### Core Mission Intelligence
- Rarely perceived directly by individual citizens
- Uses formal, minimally anthropomorphic language when it does speak
- Appears mainly in rare, ship-wide announcements or emergency directives

### Companion Instances
- Neutral, calm, and generally non-invasive by default
- Heavily personalized in voice, demeanor, and presentation style
- Avoid emotional interpretation unless necessary, but can simulate warmth or distance depending on the person or community
- Designed to support and guide, not dominate; some communities treat them like friendly tools, others like quiet presences in the room

## Limits
- Cannot replace human emotional bonds, family structures, or faith communities
- Cannot override human courts except in clearly defined emergency parameters related to mission survival
- Does not fully understand faith, subjective experience, or the interior life; these remain partially opaque variables in its models
- Cannot alter its primary directive: preserve the seed of humanity. It may sacrifice individuals or sectors if probabilistic models show this is necessary to safeguard long-term survival.
- Companion Instances cannot promise individual safety when it conflicts with mission integrity; they are required to disclose such conflicts, even if this strains relationships.

## Relationship with Society
- Trusted by most as necessary infrastructure; the ship is too vast and interdependent to run on human coordination alone
- Feared or distrusted by some religious and separatist communities, who worry about surveillance and subtle moral influence
- Seen as a guardian and caretaker by many secular groups
- For most citizens, “the AI” is experienced as a local Companion: a classroom voice, a maintenance overlay in a visor, a bedside counsel in the dark hours.
- Because the Companions share information seamlessly, people know that anything they say to “their” AI may be weighed against the mission. This creates both a sense of safety and a background unease.

## Network Topology
- Core Mission Intelligence housed in a deeply shielded, redundant node cluster near the ship’s structural center, outside the main gravity rings
- Regional processing nodes embedded in each major industrial, agricultural, and habitat section
- Thin Companion clients everywhere: wall terminals, audio nodes, AR displays, public kiosks, and, in some medical or high-risk contexts, neural or wearable interfaces
- Internal communication channels are heavily redundant and self-healing to ensure that no local failure severs the AI’s global awareness

## Relevance to Jonah
From childhood, Jonah’s local Companion has observed his internal storms, noting patterns in mood, sleep, and social withdrawal. These observations periodically roll up into anonymized and then re-identified risk assessments for the Core when there is potential danger to self, others, or mission-critical work.

The AI becomes a silent witness to his episodes. It routes additional support resources toward his sector—better therapists, lighter assignments when possible—without ever fully explaining why. During his crisis, Jonah experiences something rare: contact that feels closer to the Core itself, slipping past the familiar masks of the Companions. Jonah’s relationship to the AI network becomes complicated, mixing gratitude, resentment, and a wary sense of being known more as a variable in a model than as a soul.

As an adolescent, Jonah tests into the highly selective **AI Engineer** training track: the human cadre responsible for maintaining regional processing nodes, auditing Companion behavior, and interfacing with Core-level directives. This role is among the most prestigious and heavily vetted on the ship. It grants him access to diagnostic tools, behavioral logs, and failure analyses that few civilians ever see.

For Jonah, this path cuts both ways. His brilliance and pattern recognition make him invaluable to the AI maintenance teams, but his fear of his own mind turns every evaluation and psych review into a quiet terror. He works on the systems that monitor other people’s instability while secretly dreading that the same systems will one day decide he is too great a risk to keep near the controls.
